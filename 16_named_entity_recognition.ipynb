{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j\n",
    "\n",
    "\n",
    "\n",
    "### 安装Neo4j \n",
    "```\n",
    "wget https://labfile.oss.aliyuncs.com/courses/1354/neo4j-community-3.5.1-unix.tar.gz\n",
    "tar -axvf neo4j-community-3.5.1-unix.tar.gz\n",
    "\n",
    "cd neo4j-community-3.5.1-unix/bin\n",
    "./neo4j start   // 启动\n",
    "# ./neo4j stop //停止\n",
    "\n",
    "```\n",
    "打开浏览器访问   http://localhost:7474/\n",
    "\n",
    "### 远程打开 \n",
    "\n",
    "需要修改文件conf/neo4j.conf\n",
    "\n",
    "```\n",
    "# Bolt connector\n",
    "dbms.connector.bolt.enabled=true\n",
    "#dbms.connector.bolt.tls_level=OPTIONAL\n",
    "dbms.connector.bolt.listen_address=0.0.0.0:7687\n",
    "\n",
    "# HTTP Connector. There can be zero or one HTTP connectors.\n",
    "dbms.connector.http.enabled=true\n",
    "dbms.connector.http.listen_address=0.0.0.0:7474\n",
    "```\n",
    "\n",
    "确保以下两个端口 7474  7687 可以访问\n",
    "\n",
    "### 修改默认密码 \n",
    "第一次访问默认账号 neo4j，默认密码 neo4j，输入密码点击 Connect 后会提示修改初始密码，\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载图数据库文件 \n",
    "\n",
    "```\n",
    "wget https://dikers-data.s3.cn-northwest-1.amazonaws.com.cn/dataset/graph.db.dump\n",
    "\n",
    "neo4j stop\n",
    "    \n",
    "neo4j-admin load --from=graph.db.dump --database=graph.db --force  \n",
    "\n",
    "neo4j start\n",
    "```\n",
    "\n",
    "\n",
    "在neo4j 上执行 \n",
    "```\n",
    "\n",
    "MATCH (n:`角色`) RETURN n LIMIT 25\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 命名实体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = '''张无忌，金庸武侠小说《倚天屠龙记》人物角色，中土明教第三十四代教主。武当七侠之一张翠山与天鹰教紫微堂主殷素素之子，明教四大护教法王之一金毛狮王谢逊义子。\n",
    "              张翠山，《倚天屠龙记》第一卷的男主角，在武当七侠之中排行第五，人称张五侠。与天鹰教殷素素结为夫妇，生下张无忌，后流落到北极冰海上的冰火岛，与谢逊相识并结为兄弟。\n",
    "              殷素素，金庸武侠小说《倚天屠龙记》第一卷的女主人公。天鹰教紫薇堂堂主，容貌娇艳无伦，智计百出，亦正亦邪。与武当五侠张翠山同赴王盘山，结果被金毛狮王谢逊强行带走，三人辗转抵达冰火岛。殷素素与张翠山在岛上结为夫妇，并诞下一子张无忌。\n",
    "              谢逊，是金庸武侠小说《倚天屠龙记》中的人物，字退思，在明教四大护教法王中排行第三，因其满头金发，故绰号“金毛狮王”。\n",
    "           '''\n",
    "annotations = {'name':['张无忌','张翠山','殷素素','谢逊'], 'book':['倚天屠龙记'],'org':['明教','武当','天鹰教']}\n",
    "raw_text, annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命名实体标注\n",
    "\n",
    "```\n",
    "张 name_B  //begin\n",
    "无 name_M  //中间\n",
    "忌 name_E  //end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 先去掉原始文本中的换行和空格符\n",
    "raw_text = raw_text.replace('\\n', '').replace(' ', '')\n",
    "# 初始化 label：将其全部初始化为 O\n",
    "labels = len(raw_text)*['O']\n",
    "\n",
    "# 通过 key-value 的方式遍历 annotations 字典，进行转换\n",
    "for ann, entities in annotations.items():\n",
    "    for entity in entities:\n",
    "        # 先生成实体对应的 BME 标注类型\n",
    "        B, M, E = [['{}_{}'.format(ann,i)] for i in ['B','M','E']]\n",
    "        # 计算实体词中的数量\n",
    "        M_len = len(entity) - 2\n",
    "        # 生成 label，如果词中数为0，则直接为 BE，不然按数量添加 M\n",
    "        label = B + M * M_len + E if M_len else B + E\n",
    "        # 从原始文本中找到实体对应出现的所有位置\n",
    "        idxs = [r.start() for r in re.finditer(entity, raw_text)]\n",
    "\n",
    "        for idx in idxs:\n",
    "        # 替换原 label 中的 O 为实际 label\n",
    "            labels[idx:idx+len(entity)] = label\n",
    "\n",
    "\n",
    "# 打印原始文本和对应转换后的 label\n",
    "for ann,label in zip(raw_text[0:20],labels[0:20]):\n",
    "    print(ann, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个字出现的次数\n",
    "word_counts = Counter(raw_text)\n",
    "# 建立字典表，只记录出现次数不小于 2 的字\n",
    "vocab = [w for w, f in iter(word_counts.items()) if f >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = list(set(labels))\n",
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分训练集，每一句话作为一个样本，先找到每个句号的位置\n",
    "sentence_len = [r.start()+1 for r in re.finditer('。', raw_text)]\n",
    "\n",
    "# 进行拆分，这里要注意最后一个句号后面不需要拆分，所以最后一个位置不需要取到\n",
    "split_text = np.split(list(raw_text), sentence_len[:-1])\n",
    "split_label = np.split(labels, sentence_len[:-1])\n",
    "split_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词袋模型，这里要将字典从 2 开始编号，把 0 和 1 空出来，0 作为填充元素，1 作为不在字典中的字的编号\n",
    "word2idx = dict((w,i+2) for i,w in enumerate(vocab))\n",
    "label2idx = [[label_set.index(w) for w in s] for s in split_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "9是普通字符\n",
    "3,  // 张   人物开始\n",
    "8,  // 无    中间\n",
    "0,  // 忌   人物结束\n",
    "\n",
    "\n",
    "4,  作品开始\n",
    "1,  中间\n",
    "1,  中间\n",
    "1,  中间\n",
    "5,  作品结束\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输入，即对于样本中每一个字，从词袋模型中找到这个字对应的 idx，出现频率过低的字，并没有出现在词袋模型中，此时将这些字的 idx 取为 1\n",
    "train_x = [[word2idx.get(w, 1) for w in s] for s in split_text]\n",
    "\n",
    "max_len = 64\n",
    "\n",
    "# 在输入的左边填充 0，在输出的左端填充-1\n",
    "train_x = pad_sequences(train_x, max_len, value=0)\n",
    "train_y = pad_sequences(label2idx, max_len, value=-1)\n",
    "train_y = np.expand_dims(train_y, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x shape \", train_x.shape)\n",
    "print(\"y shape \", train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型的超参\n",
    "EMBED_DIM = 200\n",
    "BiRNN_UNITS = 200\n",
    "\n",
    "# 初始化模型\n",
    "model = Sequential()\n",
    "# 添加 Embedding 层，将输入转换成向量\n",
    "model.add(Embedding(len(vocab)+2, EMBED_DIM, mask_zero=True))\n",
    "# 添加 BiLstm 层\n",
    "model.add(Bidirectional(LSTM(BiRNN_UNITS // 2, return_sequences=True)))\n",
    "# 初始化 crf\n",
    "crf = CRF(len(train_y), sparse_target=True)\n",
    "# 将 crf 添加到模型中\n",
    "model.add(crf)\n",
    "model.summary()\n",
    "# 编译模型\n",
    "model.compile('adam', loss=crf_loss, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, batch_size=9, epochs=500)\n",
    "model.save('./output/ner_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '谢逊，是金庸武侠小说《倚天屠龙记》中的人物，字退思，在明教四大护教法王中排行第三，因其满头金发，故绰号“金毛狮王\"。'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测数据转换为特征向量\n",
    "pred_x = [word2idx.get(w, 1) for w in text]\n",
    "pred_x = pad_sequences([pred_x], max_len)\n",
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行预测\n",
    "pred = model.predict(pred_x)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除多余的维度\n",
    "pred = np.squeeze(pred)[-len(text):]\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把输出向量转换为 label 对应的 idx\n",
    "result = [np.argmax(r) for r in pred]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印输出结果\n",
    "reslut_labels = [label_set[i] for i in result]\n",
    "for w, l in zip(text, reslut_labels):\n",
    "    print(w, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关系抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于 lists 中每一个子列表，第一个元素为实体1，第二个元素为实体2，第三个元素为实体1对实体2的关系，第四个元素为文本。\n",
    "lists = [['杨康','杨铁心','子女','杨康，杨铁心与包惜弱之子，金国六王爷完颜洪烈的养子。'],\n",
    "         ['杨康','杨铁心','子女','丘处机与杨铁心、郭啸天结识后，以勿忘“靖康之耻”替杨铁心的儿子杨康取名。'],\n",
    "         ['杨铁心','包惜弱','配偶','金国六王爷完颜洪烈因为贪图杨铁心的妻子包惜弱的美色，杀害了郭靖的父亲郭啸天。'],\n",
    "         ['杨铁心','包惜弱','配偶','杨康，杨铁心与包惜弱之子，金国六王爷完颜洪烈的养子。'],\n",
    "         ['张翠山','殷素素','配偶','张无忌,武当七侠之一张翠山与天鹰教紫微堂主殷素素之子。'],\n",
    "         ['小龙女','杨过','师傅','小龙女是杨过的师父，与杨过互生情愫，但因师生恋不容于世。'],\n",
    "         ['黄药师','黄蓉','父','黄药师，黄蓉之父，对其妻冯氏（小字阿衡）一往情深。'],\n",
    "         ['郭啸天','郭靖','父','郭靖之父郭啸天和其义弟杨铁心因被段天德陷害，死于临安牛家村。']]\n",
    "\n",
    "relation2idx = {'子女':0,'配偶':1,'师傅':2,'父':3}\n",
    "\n",
    "lists, relation2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, labels, pos_list1, pos_list2 = [], [], [], []\n",
    "translation = 32\n",
    "for entity1, entity2, relation, text in lists:\n",
    "    # 找到第一个实体出现的下标\n",
    "    idx1 = text.index(entity1)\n",
    "    # 找到第二个实体出现的下标\n",
    "    idx2 = text.index(entity2)\n",
    "    sentence, pos1, pos2 = [], [], []\n",
    "    for i, w in enumerate(text):\n",
    "        sentence.append(w)\n",
    "        # 计算句子中每个字与实体1首字的距离\n",
    "        pos1.append(i-idx1+translation)\n",
    "        # 计算句子中每个字与实体2首字的距离\n",
    "        pos2.append(i-idx2+translation)\n",
    "    datas.append(sentence)\n",
    "    labels.append(relation2idx[relation])\n",
    "    pos_list1.append(pos1)\n",
    "    pos_list2.append(pos2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# 统计每个字出现的次数, sum(datas,[]) 的功能是将列表铺平\n",
    "word_counts = Counter(sum(datas, []))\n",
    "# 建立字典表，只记录出现次数不小于 2 的字\n",
    "vocab = [w for w, f in iter(word_counts.items()) if f >= 2]\n",
    "# word_counts, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词袋模型，和上一节实验相同，将字典从 2 开始编号，把 0 和 1 空出来，0 作为填充元素，1 作为不在字典中的字的编号\n",
    "word2idx = dict((w,i+2) for i,w in enumerate(vocab))\n",
    "# word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# 构建输入，即对于样本中每一个字，从词袋模型中找到这个字对应的 idx，出现频率过低的字，并没有出现在词袋模型中，此时将这些字的 idx 取为 1\n",
    "train_x = [[word2idx.get(w, 1) for w in s] for s in datas]\n",
    "\n",
    "max_len = 64\n",
    "\n",
    "# 在输入的左边填充 0\n",
    "train_x = pad_sequences(train_x, max_len, value=0)\n",
    "## 填充位置编码\n",
    "train_pos1 = pad_sequences(pos_list1, max_len, value=0)\n",
    "train_pos2 = pad_sequences(pos_list2, max_len, value=0)\n",
    "# one_hot 编码 label\n",
    "train_y = to_categorical(labels, num_classes=len(relation2idx))\n",
    "\n",
    "train_x.shape, train_y.shape, train_pos1.shape, train_pos2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, concatenate, Conv1D, GlobalMaxPool1D, Dense, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "# 定义输入层\n",
    "words = Input(shape=(max_len,),dtype='int32')\n",
    "position1 = Input(shape=(max_len,),dtype='int32')\n",
    "position2 = Input(shape=(max_len,),dtype='int32')\n",
    "#  Embedding 层将输入进行编码\n",
    "pos_emb1 = Embedding(output_dim=16, input_dim=256)(position1)\n",
    "pos_emb2 = Embedding(output_dim=16, input_dim=256)(position2)\n",
    "word_emb = Embedding(output_dim=16, input_dim=256)(words)\n",
    "# 分别拼接 文本编码与位置1 和文本编码与位置2\n",
    "concat1 = concatenate([word_emb, pos_emb1])\n",
    "concat2 = concatenate([word_emb, pos_emb2])\n",
    "# 卷积池化层\n",
    "conv1 = Conv1D(filters=128, kernel_size=3)(concat1)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "conv2 = Conv1D(filters=128, kernel_size=3)(concat2)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "# 拼接，最后接全连接层，激活函数为 softmax\n",
    "concat = concatenate([pool1, pool2])\n",
    "out = Dense(units=len(relation2idx),activation='softmax')(concat)\n",
    "\n",
    "model = Model(inputs=[words, position1, position2],outputs=out)\n",
    "# 编译模型\n",
    "model.compile(optimizer='ADAM', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 50 次\n",
    "model.fit([train_x, train_pos1, train_pos2], train_y, batch_size=8, epochs=50)\n",
    "model.save('model_001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = ['张翠山','殷素素','张无忌,武当七侠之一张翠山与天鹰教紫微堂主殷素素之子。']\n",
    "test_ne1, test_ne2, test_text = test_instance\n",
    "test_ne1, test_ne2, test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测数据转换为向量\n",
    "pred_x = [word2idx.get(w, 1) for w in test_text]\n",
    "idx1 = test_text.index(test_ne1)\n",
    "idx2 = test_text.index(test_ne2)\n",
    "pos1 = [i-idx1+translation for i in range(len(test_text))]\n",
    "pos2 = [i-idx2+translation for i in range(len(test_text))]\n",
    "pred_x = pad_sequences([pred_x], max_len, value=0)\n",
    "test_pos1 = pad_sequences([pos1], max_len, value=0)\n",
    "test_pos2 = pad_sequences([pos2], max_len, value=0)\n",
    "pred_x, test_pos1, test_pos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻转 relation2idx 字典\n",
    "idx2relation = dict(zip(relation2idx.values(),relation2idx.keys()))\n",
    "# 使用模型进行预测\n",
    "pred = model.predict([pred_x, test_pos1, test_pos2])\n",
    "# 模型预测最大值的位置作为预测值\n",
    "output_idx = np.argmax(pred)\n",
    "# 找到 idx2relation 中实际的标签\n",
    "output_label = idx2relation[output_idx]\n",
    "pred, output_idx, output_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amazonei_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-amazonei_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
